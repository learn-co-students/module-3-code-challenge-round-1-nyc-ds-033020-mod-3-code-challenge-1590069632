{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Code Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This assessment is designed to test your understanding of Module 3 material. It covers:\n",
    "\n",
    "* Gradient Descent\n",
    "* Logistic Regression\n",
    "* Classification Metrics\n",
    "* Decision Trees\n",
    "\n",
    "_Read the instructions carefully._ You will be asked both to write code and respond to a few short answer questions.\n",
    "\n",
    "### Note on the short answer questions\n",
    "\n",
    "For the short answer questions, _please use your own words._ The expectation is that you have **not** copied and pasted from an external source, even if you consult another source to help craft your response. While the short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, do your best to communicate yourself clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Gradient Descent [Suggested Time: 20 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best fit line](visuals/best_fit_line.png)\n",
    "\n",
    "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n",
    "\n",
    "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n",
    "\n",
    "![](visuals/cost_curve.png)\n",
    "\n",
    "where RSS is defined as the residual sum of squares:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) What is a more generalized name for the RSS curve above? How could a machine learning model use this curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A more generalized name is a loss curve. A machine learning model can use this curve to find what \n",
    "value of m(or another parameter) minimizes the loss(in this case RSS).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Would you rather choose a $m$ value of 0.08 or 0.05 from the RSS curve up above? Explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I would rather choose an m value of 0.05 because the loss is less than the loss at an m of 0.08.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](visuals/gd.png)\n",
    "\n",
    "### 1.3) Using the gradient descent visual from above, explain why the distance between estimates in each step is getting smaller as more steps occur with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At each step, the learning rate is multiplied by the gradient to determine where the next step will be. So as you descend\n",
    "along the curve, the gradient decreases and in turn so do the steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) What does the learning rate do in the gradient descent algorithm? Explain how a very small and a very large learning rate would affect the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The learning rate determines the size of the 'steps' your algorithm will take. If the learning rate is too small, the algorithm \n",
    "will take an unnecessarily long time to learn and arrive at the minimum loss point. Conversely, if the learning rate is too big,\n",
    "the steps will be too big and can overshoot the minimum which can lead to bouncing back and forth around the bottom of the curve.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Logistic Regression [Suggested Time: 15 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Why is logistic regression typically better than linear regession for modeling a binary target/outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In binary classification, you only have 2 outcomes, 0 and 1. Linear regression fits a straight line along the data to predict \n",
    "the outcome, and this means that you have a possibility of getting a value below 0 and above 1. Logistic regression uses logs \n",
    "and the sigmoid function to fit a line that goes from 0 to 1 and can also give probabilities for the value at each point.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) What is one advantage that logistic regression can have over other classification methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Log regression is more interpretable than other classification methods because it gives actual coefficients \n",
    "that you can interpret.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Classification Metrics [Suggested Time: 20 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cnf matrix](visuals/cnf_matrix.png)\n",
    "\n",
    "### 3.1) Using the confusion matrix above, calculate precision, recall, and F-1 score.\n",
    "\n",
    "Show your work, not just your final numeric answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to calculate precision\n",
    "tp=30\n",
    "fp=4\n",
    "precision=tp/(tp+fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to calculate recall\n",
    "tp=30\n",
    "fn=12\n",
    "recall=tp/(tp+fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7894736842105262"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here to calculate F-1 score\n",
    "f1=2*recall*precision/(recall+precision)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"visuals/many_roc.png\" width = \"700\">\n",
    "\n",
    "### 3.2) Which ROC curve from the above graph is the best? Explain your reasoning. \n",
    "\n",
    "Note: each ROC curve represents one model, each labeled with the feature(s) inside each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The ROC curve for all features is the best because it has the largest area under the curve. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Example\n",
    "\n",
    "The following cell includes code to train and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier has an accuracy score of 0.956.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Include relevant imports\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "network_df = pickle.load(open('write_data/sample_network_data.pkl', 'rb'))\n",
    "\n",
    "# partion features and target \n",
    "X = network_df.drop('Purchased', axis=1)\n",
    "y = network_df['Purchased']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "\n",
    "# scale features\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# build classifier\n",
    "model = LogisticRegression(C=1e5, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# get the accuracy score\n",
    "print(f'The classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Explain how the distribution of `y` shown below could explain the very high accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1     13\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There is a very large class imbalance which means that there is a chance to get that high of an accuracy if the model just \n",
    "always predicts the majority class(0 in this case).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) What method could you use to address the issue discovered in Question 3.3? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You could use some form of over or undersampling to balance the data used to train the model and use the f1 score as the scoring\n",
    "metric instead of or alongside accuracy to get a better grasp of the performance of the model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Decision Trees [Suggested Time: 20 min]\n",
    "---\n",
    "\n",
    "### Concepts \n",
    "You're given a dataset of **30** elements, 15 of which belong to a positive class (denoted by *`+`* ) and 15 of which do not (denoted by `-`). These elements are described by two attributes, A and B, that can each have either one of two values, true or false. \n",
    "\n",
    "The diagrams below show the result of splitting the dataset by attribute: the diagram on the left hand side shows that if we split by attribute A there are 13 items of the positive class and 2 of the negative class in one branch and 2 of the positive and 13 of the negative in the other branch. The right hand side shows that if we split the data by attribute B there are 8 items of the positive class and 7 of the negative class in one branch and 7 of the positive and 8 of the negative in the other branch.\n",
    "\n",
    "<img src=\"visuals/decision_stump.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Which one of the two attributes resulted in the best split of the original data? How do you select the best attribute to split a tree at each node? \n",
    "\n",
    "It may be helpful to discuss splitting criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splitting on attribute A results in the best split of the original data. You select the best attribute to split on at each node\n",
    "by seeing which split gives you the greatest information gain and in the case of attribute A, you can discern that there is a\n",
    "high probability of being positive if true and negative if false. On the other hand, splitting on B still gives you about a 50/50\n",
    "chance of being positive or negative.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Example\n",
    "\n",
    "In this section, you will use decision trees to fit a classification model to the wine dataset. The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Relevant imports \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the data \n",
    "wine = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'target'\n",
    "df = pd.concat([X, y.to_frame()], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "# Get the shape of the DataFrame \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "# Get the distribution of the target variable \n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Split the data into training and test sets. Create training and test sets with `test_size=0.5` and `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Fit a decision tree model with scikit-learn to the training data. Use parameter defaults, except for `random_state=1`. Use the fitted classifier to generate predictions for the test data.\n",
    "\n",
    "You can use the Scikit-learn DecisionTreeClassifier (docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree= DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "y_pred=dtree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Obtain the accuracy score of the predictions on the test set. \n",
    "\n",
    "You can use the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8764044943820225\n"
     ]
    }
   ],
   "source": [
    "# Your code imports here\n",
    "\n",
    "# Replace None with appropriate code \n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Produce a confusion matrix for the predictions on the test set. \n",
    "\n",
    "You can use the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  6,  0],\n",
       "       [ 2, 30,  2],\n",
       "       [ 0,  1, 21]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code imports here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Your code here \n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(dtree,X_test,y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6) Do the accuracy score or confusion matrix reveal any substantial problems with this model's performance? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There is a bit of a bias toward label 1 which could be due to the class imbalance and 1 being the majority class. Most cases of \n",
    "wrong predictions were classified as 1. There may be some anomolous points that are throwing it off.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
