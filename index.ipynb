{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Code Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This assessment is designed to test your understanding of Module 3 material. It covers:\n",
    "\n",
    "* Gradient Descent\n",
    "* Logistic Regression\n",
    "* Classification Metrics\n",
    "* Decision Trees\n",
    "\n",
    "_Read the instructions carefully._ You will be asked both to write code and respond to a few short answer questions.\n",
    "\n",
    "### Note on the short answer questions\n",
    "\n",
    "For the short answer questions, _please use your own words._ The expectation is that you have **not** copied and pasted from an external source, even if you consult another source to help craft your response. While the short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, do your best to communicate yourself clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Gradient Descent [Suggested Time: 20 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best fit line](visuals/best_fit_line.png)\n",
    "\n",
    "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n",
    "\n",
    "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n",
    "\n",
    "![](visuals/cost_curve.png)\n",
    "\n",
    "where RSS is defined as the residual sum of squares:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) What is a more generalized name for the RSS curve above? How could a machine learning model use this curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The RSS curve can also be referred to as the cost (or loss) function.\n",
    "A machine learning model can pick a random point on that curve, find the slope at that point, and use that to\n",
    "gradually descend down toward the point with the lowest cost (where the slope equals 0).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Would you rather choose a $m$ value of 0.08 or 0.05 from the RSS curve up above? Explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I would choose an m value of 0.05 because that has a lower RSS value,\n",
    "i.e. is closest to the minimum on the cost function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](visuals/gd.png)\n",
    "\n",
    "### 1.3) Using the gradient descent visual from above, explain why the distance between estimates in each step is getting smaller as more steps occur with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since the gradient descent is calculated using the slope of the previous point, as the slopes decrease with each\n",
    "successive step, so too will the distances between those steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) What does the learning rate do in the gradient descent algorithm? Explain how a very small and a very large learning rate would affect the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The learning rate allows you to descend more gradually toward the minimum. A very small learning rate will take too\n",
    "long to reach the minimum, whereas a very large learning rate runs the risk of overshooting the minimum value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Logistic Regression [Suggested Time: 15 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Why is logistic regression typically better than linear regession for modeling a binary target/outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linear regression tries to fit a line to numerical/continuous data, with theoretical limits of negative and\n",
    "positive infinity, whereas logistic regression uses a sigmoid curve to predict the probability of values being\n",
    "in one category or another, i.e. a 0 or 1. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) What is one advantage that logistic regression can have over other classification methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logistic regression is generally more interpretable than other classification methods, albeit in terms of log-odds.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Classification Metrics [Suggested Time: 20 min]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cnf matrix](visuals/cnf_matrix.png)\n",
    "\n",
    "### 3.1) Using the confusion matrix above, calculate precision, recall, and F-1 score.\n",
    "\n",
    "Show your work, not just your final numeric answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "# Your code here to calculate precision\n",
    "TP = 30\n",
    "TN = 54\n",
    "FP = 4\n",
    "FN = 12\n",
    "\n",
    "precision = TP / (TP+FP)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Your code here to calculate recall\n",
    "recall = TP / (TP+FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894736842105262\n"
     ]
    }
   ],
   "source": [
    "# Your code here to calculate F-1 score\n",
    "f1 = 2 * ((precision*recall) / (precision+recall))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"visuals/many_roc.png\" width = \"700\">\n",
    "\n",
    "### 3.2) Which ROC curve from the above graph is the best? Explain your reasoning. \n",
    "\n",
    "Note: each ROC curve represents one model, each labeled with the feature(s) inside each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The 'All Features' (pink) curve is the best because its AUC value is largest, i.e. closest to 1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Example\n",
    "\n",
    "The following cell includes code to train and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier has an accuracy score of 0.956.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Include relevant imports\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "network_df = pickle.load(open('write_data/sample_network_data.pkl', 'rb'))\n",
    "\n",
    "# partion features and target \n",
    "X = network_df.drop('Purchased', axis=1)\n",
    "y = network_df['Purchased']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "\n",
    "# scale features\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# build classifier\n",
    "model = LogisticRegression(C=1e5, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# get the accuracy score\n",
    "print(f'The classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Explain how the distribution of `y` shown below could explain the very high accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1     13\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518518518518518"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## equivalent to 257 / (257+13)\n",
    "1 - y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The distribution of 'y' is very imbalanced, with a very low value for 1 as compared to 0,\n",
    "so one could simply always predict 0 and have an accuracy score of 95.2%.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) What method could you use to address the issue discovered in Question 3.3? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You could upsample the minority class (the values of '1') by adding samples (with replacement) of the minority class\n",
    "until each class has an equal quantity (unless some other ratio is desired).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Decision Trees [Suggested Time: 20 min]\n",
    "---\n",
    "\n",
    "### Concepts \n",
    "You're given a dataset of **30** elements, 15 of which belong to a positive class (denoted by *`+`* ) and 15 of which do not (denoted by `-`). These elements are described by two attributes, A and B, that can each have either one of two values, true or false. \n",
    "\n",
    "The diagrams below show the result of splitting the dataset by attribute: the diagram on the left hand side shows that if we split by attribute A there are 13 items of the positive class and 2 of the negative class in one branch and 2 of the positive and 13 of the negative in the other branch. The right hand side shows that if we split the data by attribute B there are 8 items of the positive class and 7 of the negative class in one branch and 7 of the positive and 8 of the negative in the other branch.\n",
    "\n",
    "<img src=\"visuals/decision_stump.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Which one of the two attributes resulted in the best split of the original data? How do you select the best attribute to split a tree at each node? \n",
    "\n",
    "It may be helpful to discuss splitting criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Attribute 'A' results in a much better split of the data because it results in a lower impurity and entropy\n",
    "than splitting on Attribute 'B'. Attribute 'B' results in an almost 50-50 split, which is exactly what you don't want.\n",
    "\n",
    "You can use information gain to determine the best attribute to split a tree at each node. Information gain is\n",
    "highest when the entropy of the split is lowest (i.e. the branches are farthest away from a 50-50 split).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Example\n",
    "\n",
    "In this section, you will use decision trees to fit a classification model to the wine dataset. The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Relevant imports \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the data \n",
    "wine = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X = pd.DataFrame(X, columns=wine.feature_names)\n",
    "y = pd.Series(y)\n",
    "y.name = 'target'\n",
    "df = pd.concat([X, y.to_frame()], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "# Get the shape of the DataFrame \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "# Get the distribution of the target variable \n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Split the data into training and test sets. Create training and test sets with `test_size=0.5` and `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Fit a decision tree model with scikit-learn to the training data. Use parameter defaults, except for `random_state=1`. Use the fitted classifier to generate predictions for the test data.\n",
    "\n",
    "You can use the Scikit-learn DecisionTreeClassifier (docs [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_tree = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "d_tree.fit(X_train, y_train)\n",
    "\n",
    "y_preds = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Obtain the accuracy score of the predictions on the test set. \n",
    "\n",
    "You can use the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8764044943820225\n"
     ]
    }
   ],
   "source": [
    "# Your code imports here\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Replace None with appropriate code \n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Produce a confusion matrix for the predictions on the test set. \n",
    "\n",
    "You can use the `sklearn.metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  6  0]\n",
      " [ 2 30  2]\n",
      " [ 0  1 21]]\n"
     ]
    }
   ],
   "source": [
    "# Your code imports here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Your code here \n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # doctest: +SKIP\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "\n",
    "plot_confusion_matrix(d_tree, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6) Do the accuracy score or confusion matrix reveal any substantial problems with this model's performance? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The confusion matrix shows that whichever class that is labeled as '1' seems to be giving this model the most trouble.\n",
    "This model generally tends to overpredict class '1' or miss wines that are actually class '1'.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
